\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{color}
\usepackage{caption}
\usepackage{float}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[acronym]{glossaries}
\usepackage[nottoc]{tocbibind}
\usepackage{tikz}
\graphicspath{{./images/}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\renewcommand{\algorithmicrequire}{\textbf{Input}}
\renewcommand{\algorithmicensure}{\textbf{Output}}

\title{%
      Homework 2 \\
      Kd-Trees
}
\author{%
  Juan Pablo Royo Sales\\
  \small{Universitat Polit√®cnica de Catalunya}
}
\date\today

\pagestyle{fancy}
\fancyhf{}
\fancyhead[C]{}
\fancyhead[R]{Juan Pablo Royo Sales - UPC MIRI}
\fancyhead[L]{ADM - Kd-Trees}
\fancyfoot[L,C]{}
\fancyfoot[R]{Page \thepage{} of \pageref{LastPage}}
\setlength{\headheight}{15pt}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\makeglossaries

\newacronym{kdt}{K-d Tree}{K-Dimensional Binary Search Tree}
\newacronym{bst}{BST}{Binary Search Tree}
\newacronym{nns}{NNS}{Nearest Neighbor Search}
\newacronym{lsh}{LSH}{Locality Sensitivity Hashing}

\begin{document}

\maketitle

\medskip

\section{Introduction}
A \textbf{\acrfull{kdt}} was defined by first time in \cite{bentley} is a Multidimensional Data Structure and a generalization of a \textbf{\acrfull{bst}} but with discriminators by level. In the following sections we are going to describe formally this structure.

\acrshort{kdt} can be \textbf{Standard} which is the definition given by \cite{bentley} or \textbf{Relaxed} which implements a Randomized selection of the discriminators at each level. In this article we are going to describe and focus only in \textbf{Standard} \acrshort{kdt}.

The idea of this article is to show the power of \acrshort{kdt} for running \acrfull{nns} algorithm in order to be tested against \acrfull{lsh} in a posterior work.

\section{Definition}
A \textbf{\acrshort{kdt}} of size $n \geq 0$ contains a Set $n$ $K$-dimensional records, such that each key $x = (x_0, \dots , x_{K-1}) \in D$ where  $D = D_0 \times \dots \times D_{K-1}$, and each $D_j, 0 < j < K$, is a totally ordered domain.

A \textbf{\acrshort{kdt}} $T$ is a \acrshort{bst} such that:

\begin{itemize}
    \item If $n = 0$ then $T$ is empty
    \item Root's $T$ stores a pair $(x,d)$ given that $x$ is the key of one of the $K$-dimensional points and $d$ is the level or discriminant of the node such that $ d = \text{root level } mod K, 0 \leq j < K$
    \item A left $L$ and right $R$ subtree is build recursively with the following form: $ L = \{ x_i | x_i < x_{root} \}$ and $R = \{x_j | x_j > x_{root}\}$.
    \item Each level of the tree use the same discriminator $d$.
\end{itemize}

The following example that was taken from \cite{vtech_page} illustrate the definition given above:

\begin{minipage}[t]{\linewidth}
  \includegraphics[width=\textwidth]{KDTree}
  \captionof{figure}{Example of KDTree}
  \label{fig:kdtree_example}
\end{minipage}

As we can see in this example \acrshort{kdt} divides the \textit{space} in \textit{hyperrectangles}. As we can see here point $A$ which is the first inserted use as a discriminator dimension $x$, so in the next level discriminator will be $y$ and after that $x$ again.

\acrshort{kdt} are optimal for doing any kind of range query, as well as exact search, partial matches and of course \acrshort{nns} searches.

\section{Cost Analysis}
In the case of cost analysis on \acrshort{kdt} we should distinguish different kinds of cost:

\begin{itemize}
  \item Construction cost: $\Theta(n\log{n})$ worst case
  \item Storage cost: $\Theta(n)$ worst case
  \item Range Query cost: $\Theta(R + n^{1 - \frac{s}{K} + \Theta(\frac{s}{K})})$ in average, where $R$ is the number of points in the range.
  \item Near Neighbor Search cost: $O(\log{n} + R)$ according to \cite{fried} average case for small answer.
\end{itemize}

We are going to focusing in the Cost analysis of \acrshort{nns} which is the goal of our work for doing predictions and comparing in a future work with \acrshort{lsh}.


\section{Near Neighbor Search Analysis}




\bibliographystyle{alpha}
\bibliography{Homework2_jproyo}

\printglossaries

\end{document}

